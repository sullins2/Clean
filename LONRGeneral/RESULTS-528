
Updated TigerGame:

    Much better way of handling the 2 MDPs and switching
    Renamed the states to match the diagram

    Q Avg
        LEFT : OL :  -81.9170253542367  OR :  -8.082691884759182  L :  3.4800462233293454
        LEFTLEFT : OL :  -94.78120581859311  OR :  4.781771340601338  L :  3.6525952648882942
        LEFTRIGHT : OL :  -34.48977347701781  OR :  -55.494109145747586  L :  2.657864257312623
        RIGHT : OL :  -8.073863457852902  OR :  -81.9244399761224  L :  3.3073437122431546
        RIGHTLEFT : OL :  -56.23327782839549  OR :  -33.74183920324233  L :  2.8898255973198874
        RIGHTRIGHT : OL :  4.662477614753841  OR :  -94.65201545760156  L :  3.4897870146402754
        START : OL :  -45.26921989380753  OR :  -44.73078010619247  L :  2.3689884594107364


    Pi sums: 
        LEFT : L :  46760.81764941639  OL :  0.0  OR :  5.182350583603926
        LEFTLEFT : L :  43.910943724180406  OL :  0.0  OR :  43681.08905627582
        LEFTRIGHT : L :  18851.13269758332  OL :  4.867302416678312  OR :  0.0
        RIGHT : L :  46471.6252872065  OL :  6.374712793498375  OR :  0.0
        RIGHTLEFT : L :  18828.491436212273  OL :  0.0  OR :  0.5085637877268158
        RIGHTRIGHT : L :  64.19053846833567  OL :  43571.809461531666  OR :  0.0
        START : L :  99997.81538598679  OL :  0.0  OR :  2.1846140132123955


-------

Update/review process for paper
"Hey do you have code for exp3?" Can we say yes (if we do) and show that?
    i.e. How much "more" can we add on as it gets reviewed?
August?
September?

-------

Three versions of LONR-A to try and improve or make more accurate?
Original is only one that works..

Original:

        Essentially, pick the current best action and take that action.
        Next state depends not only on this action but on noise
        The value of the current state is not influenced by the next state chosen.
        It is "on-policy" in action selection, but isn't updating s by s'
        Instead it is update s by the Exp[s'] for all s' given from the action it chose

        # Begin with start state
        currentState = self.M.startState

        done = False

        # Episode loop - until terminal state is reached
        while done == False:

            if currentState is terminal:
                QUpdate(terminal)
                done = True


            # otherwise

            # Get possible actions
            a = self.M.getActions(currentState, 0)

            # Update Q of actions
            self.QUpdate(n, currentState, a, currentState)

            # Q Backup
            for n in range(self.M.N):
                self.QBackup(n)

            # Update regrets
            self.regretUpdate(n, self.M.getStateRep(currentState), t)

            # Epsilon Greedy action selection
            if np.random.randint(0, 100) < int(self.epsilon):
                randomAction = totalActions[randomAction]
            else:
                randomAction = np.random.choice(totalActions, p=totalActionsProbs)


            # Get next possible successor states
            nextPossStates = self.M.getNextStatesAndProbs(currentState, randomAction, 0)

            # Set current state to next state
            currentState = np.random.choice(nextStates, p=nextStateProbs)


LONR-A2:

        Main difference:
            Update currentState based on actualy nextState
            Q[currentState][randomAction] = reward[currentState

        # Start at start state
        currentState = self.M.startState


        done = False

        # Episode loop - until terminal state is reached
        while done == False:

            # 1. Pick a random action epsilon greedy
            if np.random.randint(0, 100) < int(self.epsilon):
                randomAction = totalActions[randomAction]
            else:
                randomAction = np.random.choice(totalActions, p=totalActionsProbs)


            # 2. Get the possible successor states
            nextPossStates = self.M.getNextStatesAndProbs(currentState, randomAction, 0)

            # Pick a successor state as nextState
            nextState = nextPossStates[0][0]
            nextProb = nextPossStates[0][1]
            nextReward = nextPossStates[0][2]

            tempValue = 0.0

            # Loop thru actions in s_prime for player n
            for a_current_prime in self.M.getActions(nextState, n):
                tempValue += self.M.Q[n][self.M.getStateRep(nextState)][a_current_prime] * self.M.pi[n][self.M.getStateRep(nextState)][a_current_prime]

            Value = nextProb * (nextReward + self.gamma * tempValue)

            # alpha is usually 1.0 here
            self.M.Q_bu[n][self.M.getStateRep(currentState)][randomAction] = (1.0 - self.alpha)*self.M.Q[n][self.M.getStateRep(currentState)][randomAction] + (self.alpha)*Value

            # Backup/etc
            self.M.Q[0][self.M.getStateRep(currentState)][randomAction] = self.M.Q_bu[n][self.M.getStateRep(currentState)][randomAction]
            self.M.QSums[0][self.M.getStateRep(currentState)][randomAction] += self.M.Q[n][self.M.getStateRep(currentState)][randomAction]
            self.M.QTouched[n][self.M.getStateRep(currentState)][randomAction] += 1.0

            # Set done if terminal
            if nextState is terminal:
                done = True
                continue

            # Update regrets/policy
            self.regretUpdate(n, self.M.getStateRep(currentState), t)

            # Set current state as next state
            currentState = nextState


Results:

    self.grid = [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',
                     ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',
                     ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ',
                     ' ', -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 200]

    Opt Start Q Up = 187 (13 steps to goal) *took out 'exit' action for now

    RM+ is on because it is faster
    alpha = 1.0
    epsilon:  20

    LONR-A:
        noise = 0

        At iters=5000, still stuck on sub-optimal (start-up is 185, not 187)

        At iters=10,000:

        Q for: Bottom left (start state)
            {0: 187.0, 1: -101.0, 2: 186.0, 3: 186.0}

        Q Avg for: same
            36 : 0 :  185.45717850283836  1 :  -100.98812865742099  2 :  184.41397301252326  3 :  184.41397301252326

        Pi sums (notable)

            12 : 0 :  0.012777744111287553  1 :  0.979192947260819  2 :  0.002623536436931459  3 :  0.005405772190961963
            24 : 0 :  0.001702412409575544  1 :  0.9979779646296948  2 :  9.183297055265521e-06  3 :  0.00031043966367444046
            25 : 0 :  0.000706514676229005  1 :  0.9988903250808423  2 :  0.0  3 :  0.00040316024292876885
            26 : 0 :  0.00032538443096954056  1 :  0.9989416472937993  2 :  0.0004379589189893508  3 :  0.0002950093562418237
            27 : 0 :  0.14871378990708461  1 :  0.8508338177506202  2 :  0.00012467602772174772  3 :  0.0003277163145734938
            28 : 0 :  0.04438753984632402  1 :  0.9550838145947164  2 :  5.307010560951016e-05  3 :  0.0004755754533501013
            29 : 0 :  0.07731734605418647  1 :  0.9222780505384387  2 :  8.87941751021133e-05  3 :  0.00031580923227258806
            30 : 0 :  0.012605818536645875  1 :  0.9846555778339058  2 :  0.000380545898486421  3 :  0.0023580577309620632
            31 : 0 :  0.011263029035997536  1 :  0.9880892214657021  2 :  7.514277126540428e-05  3 :  0.0005726067270350204
            32 : 0 :  0.025464704026153962  1 :  0.9739748555878738  2 :  0.00012227928588897041  3 :  0.00043816110008328726
            33 : 0 :  0.0028077187731290845  1 :  0.99620903397757  2 :  0.0001274534794799898  3 :  0.0008557937698209848
            34 : 0 :  0.0  1 :  0.9999333599893376  2 :  6.66400106624017e-05  3 :  0.0
            35 : 0 :  0.0  1 :  6.856829402084476e-05  2 :  0.9999314317059792  3 :  0.0
            36 : 0 :  0.9966527887939778  1 :  0.00010646144425734444  2 :  0.0016203748808823453  3 :  0.0016203748808823453

            27 is off but I am sticking with these at 10,000 but for the record at iters=100,000
                24 : 0 :  0.07542103905079575  1 :  0.9245448043161019  2 :  0.0  3 :  3.4156633102336604e-05
                25 : 0 :  0.0029877698312087  1 :  0.9965199980785531  2 :  7.2053377141786635e-06  3 :  0.0004850267525240198
                26 : 0 :  0.014988485167513879  1 :  0.9849007742543836  2 :  2.411602751796811e-05  3 :  8.662455058449774e-05
                27 : 0 :  0.003780011664420835  1 :  0.9959400071555807  2 :  3.165610698359611e-05  3 :  0.0002483250730147483
                28 : 0 :  0.005388762734779044  1 :  0.9945094296931337  2 :  6.18512064863925e-05  3 :  3.995636560092682e-05
                29 : 0 :  0.008632335155831668  1 :  0.9913232076218764  2 :  1.0755463775598003e-05  3 :  3.37017585163245e-05
                30 : 0 :  0.006642595401184079  1 :  0.9931786543360891  2 :  5.3583535191306195e-05  3 :  0.00012516672753552045
                31 : 0 :  0.0012237458039315986  1 :  0.9984338213719167  2 :  4.5425638230217136e-05  3 :  0.00029700718592139813
                32 : 0 :  0.0015993075410595519  1 :  0.9982781419710665  2 :  5.598874325198268e-05  3 :  6.65617446219969e-05
                33 : 0 :  0.0009006386579209788  1 :  0.9990848591304918  2 :  1.4502211587267058e-05  3 :  0.0
                34 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                35 : 0 :  0.0  1 :  9.263376315399436e-06  2 :  0.9999814732473691  3 :  9.263376315399436e-06
                36 : 0 :  0.9993132009519119  1 :  2.994885480737871e-05  2 :  0.00032842509664034766  3 :  0.00032842509664034766

                And here is the pi itself (at iteration 100,000) as more evidence:
                    24 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0  RIGHT
                    25 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                    26 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                    27 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                    28 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                    29 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                    30 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                    31 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                    32 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                    33 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                    34 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                    35 : 0 :  0.0  1 :  0.0  2 :  1.0  3 :  0.0   DOWN
                    36 : 0 :  1.0  1 :  0.0  2 :  0.0  3 :  0.0  UP



    LONR-A2:
        noise = 0

        At iters=5000:
            Same, still sub-opt
            Q for: Bottom left (start state)
            {0: 185.0, 1: -101.0, 2: 184.0, 3: 184.0}

        At iters=10,000:

            Q for: Bottom left (start state)
            {0: 187.0, 1: -101.0, 2: 186.0, 3: 186.0}

            Q Avg: same (note: slightly different than LONR-AOriginal)
            36 : 0 :  184.24754625183883  1 :  -100.99048157572331  2 :  182.44554652903594  3 :  182.5242848289001

            Pi sums (notable):
            12 : 0 :  0.0022612858632509196  1 :  0.9948180248774414  2 :  0.001137733682821719  3 :  0.00178295557648588
            24 : 0 :  0.6047207946845164  1 :  0.39400281634606554  2 :  0.0005952728113636856  3 :  0.0006811161580542613
            25 : 0 :  0.18985533902433993  1 :  0.8084078674093234  2 :  0.00023712699336604076  3 :  0.0014996665729705907
            26 : 0 :  0.036845151042969294  1 :  0.9348472733078004  2 :  0.00026167144021741894  3 :  0.028045904209012883
            27 : 0 :  0.1495081493358026  1 :  0.8468966864457761  2 :  0.0007435943870971285  3 :  0.002851569831324255
            28 : 0 :  0.021621362712461158  1 :  0.9470587595409155  2 :  0.0005428786393693935  3 :  0.030776999107253903
            29 : 0 :  0.048548301006511356  1 :  0.9474590137709087  2 :  0.0012403406675219454  3 :  0.0027523445550579457
            30 : 0 :  0.0020651936975141214  1 :  0.995705118711572  2 :  0.00043388361212279633  3 :  0.0017958039787911747
            31 : 0 :  0.0017611570714267562  1 :  0.9969287987204721  2 :  0.0001722168449873998  3 :  0.0011378273631136662
            32 : 0 :  0.0011216645822832104  1 :  0.9970750998449902  2 :  0.0008062559755697305  3 :  0.0009969795971568566
            33 : 0 :  0.0005319045743188229  1 :  0.998176068542187  2 :  0.00021295680370425867  3 :  0.001079070079789912
            34 : 0 :  0.0001550207340231756  1 :  0.9998023607296794  2 :  4.2618536297345004e-05  3 :  0.0
            35 : 0 :  9.79585439442028e-05  1 :  0.0  2 :  0.999862858038478  3 :  3.918341757768112e-05
            36 : 0 :  0.9949957797596535  1 :  0.00015028188006693634  2 :  0.0024081672149607256  3 :  0.0024457711453188353

            Pi:
                24 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0  RIGHT
                25 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                26 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                27 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                28 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                29 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                30 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                31 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                32 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                33 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                34 : 0 :  0.0  1 :  1.0  2 :  0.0  3 :  0.0
                35 : 0 :  0.0  1 :  0.0  2 :  1.0  3 :  0.0  DOWN
                36 : 0 :  1.0  1 :  0.0  2 :  0.0  3 :  0.0  UP



    Non-Deterministic results (the *original* reason for the switch)

    LONR-A:



        noise = 0.2

        Q for: Bottom left (start state) (West opt = 170.23]
            {0: 150.21037762806571, 1: -45.95324941598541, 2: 142.2103776280656, 3: 170.2337529200729}

            Note: These are what LONR-V gets (and what VI gets via Berkeley code)
            LONR-V:
            Q for: Bottom left (start state) (West opt = 170.23]
            {0: 150.21037762806571, 1: -45.95324941598541, 2: 142.2103776280656, 3: 170.2337529200729}

        Goes up two states and crosses
        Pi Sums:
            12 : 0 :  0.003504568938770235  1 :  0.9960036360526489  2 :  4.9032387876044415e-05  3 :  0.0004427626207049432   RIGHT
            13 : 0 :  0.03556563177817583  1 :  0.9640673789123423  2 :  5.898156284128979e-06  3 :  0.0003610911531978585
            14 : 0 :  0.03777516315108313  1 :  0.961721435898723  2 :  0.00034863811253436824  3 :  0.0001547628376595038
            15 : 0 :  0.031174432297565623  1 :  0.9687830205460027  2 :  0.0  3 :  4.254715643171181e-05
            16 : 0 :  0.03259772202442814  1 :  0.9673321010718275  2 :  0.0  3 :  7.017690374426025e-05
            17 : 0 :  0.014516840665698224  1 :  0.9853949943959678  2 :  8.816493833393643e-05  3 :  0.0
            18 : 0 :  0.023800270229484187  1 :  0.9756737083078907  2 :  0.0003630547944322394  3 :  0.0001629666681929844
            19 : 0 :  0.016892381927955342  1 :  0.9827297874485352  2 :  0.00031677604779633926  3 :  6.105457571316205e-05
            20 : 0 :  0.011494957412276043  1 :  0.9877231289084982  2 :  0.0006757650374530191  3 :  0.00010614864177272706
            21 : 0 :  0.00027858484772122803  1 :  0.9991647327365449  2 :  0.00045988502717274457  3 :  9.679738856106761e-05
            22 : 0 :  0.00010779016038511666  1 :  0.9996298795333326  2 :  0.00011466199917096936  3 :  0.00014766830711135693
            23 : 0 :  1.631636263372512e-05  1 :  0.00017195166318050874  2 :  0.9997614473246196  3 :  5.028464956623263e-05   DOWN
            24 : 0 :  0.9996393248993442  1 :  0.0003344159756098008  2 :  0.0  3 :  2.6259125045953458e-05                     UP
            25 : 0 :  0.99924923486574  1 :  0.0004179430753035169  2 :  0.0001074575542660648  3 :  0.00022536450469036448     UP
            26 : 0 :  0.9948671605200414  1 :  0.00163335488422183  2 :  0.0018049356010630853  3 :  0.0016945489946735563
            27 : 0 :  0.9967762894934965  1 :  0.0017380696510888572  2 :  0.0005915922999493879  3 :  0.0008940485554652274
            28 : 0 :  0.9982438609815649  1 :  0.0011522908881420985  2 :  0.00027437351381013356  3 :  0.0003294746164828343
            29 : 0 :  0.9978773706318099  1 :  0.0011332113329596191  2 :  0.0004891063472684513  3 :  0.000500311687962027
            30 : 0 :  0.9937404503090121  1 :  0.0037968461356740267  2 :  0.0015842078168030941  3 :  0.000878495738510794
            31 : 0 :  0.9946328131257689  1 :  0.0011455988501656768  2 :  0.003487729254181735  3 :  0.0007338587698836032
            32 : 0 :  0.995064415666547  1 :  0.0035944531578988225  2 :  0.0005350838827570218  3 :  0.0008060472927970612
            33 : 0 :  0.9942901324901459  1 :  0.0034260428194303303  2 :  0.0019526199927681219  3 :  0.0003312046976556203
            34 : 0 :  0.9973590883687525  1 :  0.0018846449667768818  2 :  0.0006243424381773667  3 :  0.00013192422629316133
            35 : 0 :  0.00013723606563804968  1 :  6.688613371557507e-05  2 :  0.9997958778006464  3 :  0.0                     SOUTH
            36 : 0 :  0.0015036259495693931  1 :  2.1539793047333584e-05  2 :  3.2355760396351195e-05  3 :  0.9984424784969869  WEST


    LONR-A2:
        noise = 0.2

        Q for: Bottom left (start state) (West opt = 170.23]
            {0: -10.100000000000001, 1: -0.2566109287179605, 2: -2.7447661624280686, 3: -2.4847260828914974}

        Pi Sums
            0 : 0 :  0.13171201775581692  1 :  0.6187596739559829  2 :  0.14094566407013848  3 :  0.10858264421806177
            1 : 0 :  0.08102875520922652  1 :  0.7291219378677598  2 :  0.09750097788920986  3 :  0.09234832903380374
            2 : 0 :  0.07007316116464091  1 :  0.8015272237350576  2 :  0.08844157561839226  3 :  0.039958039481909194
            3 : 0 :  0.04921215515858664  1 :  0.880530827792  2 :  0.03516746588802562  3 :  0.03508955116138773
            4 : 0 :  0.04318646307997573  1 :  0.8821186653740034  2 :  0.03588715898689897  3 :  0.03880771255912184
            5 : 0 :  0.033944879384791314  1 :  0.8508621796172664  2 :  0.08508996891557047  3 :  0.03010297208237199
            6 : 0 :  0.0458339668447812  1 :  0.8512898806258591  2 :  0.07992227169855011  3 :  0.02295388083080937
            7 : 0 :  0.045459906645266876  1 :  0.810970718804621  2 :  0.11707947941028866  3 :  0.026489895139823624
            8 : 0 :  0.028011590206074216  1 :  0.8665073477995963  2 :  0.07513614135290433  3 :  0.030344920641425195
            9 : 0 :  0.03326263829765744  1 :  0.805102266292421  2 :  0.13457348631477098  3 :  0.027061609095150523
            10 : 0 :  0.028800418968883367  1 :  0.8335561720287331  2 :  0.11629584113739577  3 :  0.021347567864987788
            11 : 0 :  0.04330369111756917  1 :  0.043557369310461155  2 :  0.893692597830664  3 :  0.01944634174130563
            12 : 0 :  0.1850848977443184  1 :  0.5000495480367219  2 :  0.20610779181506145  3 :  0.10875776240389837  MIXED
            13 : 0 :  0.2172197109664678  1 :  0.662008965866947  2 :  0.02793351727116109  3 :  0.0928378058954241
            14 : 0 :  0.235043583563108  1 :  0.6872709035124034  2 :  0.037200278323322684  3 :  0.04048523460116588
            15 : 0 :  0.4073623382720354  1 :  0.5310771359667354  2 :  0.02306947161197663  3 :  0.03849105414925255
            16 : 0 :  0.40171193245031916  1 :  0.53199331796399  2 :  0.03490297408879964  3 :  0.03139177549689119
            17 : 0 :  0.23823054093515605  1 :  0.7213067242736712  2 :  0.017183463256585842  3 :  0.023279271534586855
            18 : 0 :  0.08832941592239549  1 :  0.8651560066491897  2 :  0.01717440743723653  3 :  0.02934016999117819
            19 : 0 :  0.06593103783705745  1 :  0.7988841902919258  2 :  0.1004937368817753  3 :  0.03469103498924143
            20 : 0 :  0.0426729844584102  1 :  0.8278668202359667  2 :  0.10258633199545784  3 :  0.026873863310165214
            21 : 0 :  0.03571945159056485  1 :  0.8123574951263617  2 :  0.12122903803737194  3 :  0.03069401524570179
            22 : 0 :  0.02645491868300717  1 :  0.8460818206796473  2 :  0.10634987064812074  3 :  0.02111338998922469
            23 : 0 :  0.019114069508819904  1 :  0.02708708289697147  2 :  0.9382707955937555  3 :  0.01552805200045319
            24 : 0 :  0.17620827771865014  1 :  0.11472650902434829  2 :  0.6576681756546174  3 :  0.05139703760238419  DOWN?
            25 : 0 :  0.9011051084132766  1 :  0.03640029955462809  2 :  0.005506115421658521  3 :  0.05698847661043674
            26 : 0 :  0.8927647519142824  1 :  0.05678153539717619  2 :  0.012291625683399353  3 :  0.03816208700514222
            27 : 0 :  0.9237519197704283  1 :  0.04517499630407957  2 :  0.004602239323102041  3 :  0.02647084460239004
            28 : 0 :  0.5600911413719261  1 :  0.3189446692298352  2 :  0.014291875724554795  3 :  0.10667231367368392
            29 : 0 :  0.9026441212306071  1 :  0.04697179049643247  2 :  0.0033750130649125142  3 :  0.047009075208047944
            30 : 0 :  0.6217322958424931  1 :  0.32233952989620873  2 :  0.013192412480870722  3 :  0.04273576178042742
            31 : 0 :  0.15407512188725986  1 :  0.8050771578262966  2 :  0.008069908676556903  3 :  0.03277781160988664
            32 : 0 :  0.3591991933962099  1 :  0.5988489851494344  2 :  0.003454667951888451  3 :  0.03849715350246726
            33 : 0 :  0.12537074006233143  1 :  0.8443219270273074  2 :  0.002097553468609906  3 :  0.028209779441751143
            34 : 0 :  0.07148233864622977  1 :  0.8986679404704113  2 :  0.0014947008499195341  3 :  0.028355020033439444
            35 : 0 :  0.01305669519692399  1 :  0.021023361704006614  2 :  0.9574882366230653  3 :  0.008431706476004077   SOUTH
            36 : 0 :  0.028071025890991322  1 :  0.003930801783920245  2 :  0.01657810368786742  3 :  0.9514200686372211   WEST


        At 100k iterations:
            Q for: Bottom left (start state) (West opt = 170.23]
                {0: -1.5779489401879125, 1: -80.80000000000001, 2: -10.100000000000001, 3: -2.4475298695674006}

        Also:
            Q for: State above bottom right terminal
                {0: 1.1101361749146466, 1: 126.45835928693042, 2: 159.20000000000002, 3: 3.329042529604314}

        We might have already talked about why this is incorrect, but here is one more big test.


Tiger Game VI
